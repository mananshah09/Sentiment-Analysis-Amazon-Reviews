{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TgR0I4s099nN",
    "outputId": "650ee870-54b0-4743-8703-70b2f686a52f"
   },
   "source": [
    "## Import revelant libraries for the assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Manan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ap3wSlnK99nP"
   },
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "h2ly4AyUHmqg"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\Manan\\Downloads\\amazon_reviews_us_Office_Products_v1_00.tsv', delimiter = '\\t', quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 999
    },
    "id": "8fqM6sJBIOLX",
    "outputId": "165b1ab4-4f4a-45f7-e8de-e6332c1be4e6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>43081963</td>\n",
       "      <td>R18RVCKGH1SSI9</td>\n",
       "      <td>B001BM2MAC</td>\n",
       "      <td>307809868</td>\n",
       "      <td>Scotch Cushion Wrap 7961, 12 Inches x 100 Feet</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great product.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>10951564</td>\n",
       "      <td>R3L4L6LW1PUOFY</td>\n",
       "      <td>B00DZYEXPQ</td>\n",
       "      <td>75004341</td>\n",
       "      <td>Dust-Off Compressed Gas Duster, Pack of 4</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Phffffffft, Phfffffft. Lots of air, and it's C...</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>21143145</td>\n",
       "      <td>R2J8AWXWTDX2TF</td>\n",
       "      <td>B00RTMUHDW</td>\n",
       "      <td>529689027</td>\n",
       "      <td>Amram Tagger Standard Tag Attaching Tagging Gu...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>but I am sure I will like it.</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>52782374</td>\n",
       "      <td>R1PR37BR7G3M6A</td>\n",
       "      <td>B00D7H8XB6</td>\n",
       "      <td>868449945</td>\n",
       "      <td>AmazonBasics 12-Sheet High-Security Micro-Cut ...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>and the shredder was dirty and the bin was par...</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>24045652</td>\n",
       "      <td>R3BDDDZMZBZDPU</td>\n",
       "      <td>B001XCWP34</td>\n",
       "      <td>33521401</td>\n",
       "      <td>Derwent Colored Pencils, Inktense Ink Pencils,...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642429</th>\n",
       "      <td>US</td>\n",
       "      <td>53005790</td>\n",
       "      <td>RLI7EI10S7SN0</td>\n",
       "      <td>B00000DM9M</td>\n",
       "      <td>223408988</td>\n",
       "      <td>PalmOne III Leather Belt Clip Case</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Great value! A must if you hate to carry thing...</td>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "      <td>1998-12-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642430</th>\n",
       "      <td>US</td>\n",
       "      <td>52188548</td>\n",
       "      <td>R1F3SRK9MHE6A3</td>\n",
       "      <td>B00000DM9M</td>\n",
       "      <td>223408988</td>\n",
       "      <td>PalmOne III Leather Belt Clip Case</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Attaches the Palm Pilot like an appendage</td>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "      <td>1998-11-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642431</th>\n",
       "      <td>US</td>\n",
       "      <td>52090046</td>\n",
       "      <td>R23V0C4NRJL8EM</td>\n",
       "      <td>0807865001</td>\n",
       "      <td>307284585</td>\n",
       "      <td>Gods and Heroes of Ancient Greece</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Excellent information, pictures and stories, I...</td>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "      <td>1998-10-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642432</th>\n",
       "      <td>US</td>\n",
       "      <td>52503173</td>\n",
       "      <td>R13ZAE1ATEUC1T</td>\n",
       "      <td>1572313188</td>\n",
       "      <td>870359649</td>\n",
       "      <td>Microsoft EXCEL 97/ Visual Basic Step-by-Step ...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>class text</td>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "      <td>1998-08-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642433</th>\n",
       "      <td>US</td>\n",
       "      <td>52585611</td>\n",
       "      <td>RE8J5O2GY04NN</td>\n",
       "      <td>1572313188</td>\n",
       "      <td>870359649</td>\n",
       "      <td>Microsoft EXCEL 97/ Visual Basic Step-by-Step ...</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Microsoft's Finest</td>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "      <td>1998-07-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2642434 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0                US     43081963  R18RVCKGH1SSI9  B001BM2MAC       307809868   \n",
       "1                US     10951564  R3L4L6LW1PUOFY  B00DZYEXPQ        75004341   \n",
       "2                US     21143145  R2J8AWXWTDX2TF  B00RTMUHDW       529689027   \n",
       "3                US     52782374  R1PR37BR7G3M6A  B00D7H8XB6       868449945   \n",
       "4                US     24045652  R3BDDDZMZBZDPU  B001XCWP34        33521401   \n",
       "...             ...          ...             ...         ...             ...   \n",
       "2642429          US     53005790   RLI7EI10S7SN0  B00000DM9M       223408988   \n",
       "2642430          US     52188548  R1F3SRK9MHE6A3  B00000DM9M       223408988   \n",
       "2642431          US     52090046  R23V0C4NRJL8EM  0807865001       307284585   \n",
       "2642432          US     52503173  R13ZAE1ATEUC1T  1572313188       870359649   \n",
       "2642433          US     52585611   RE8J5O2GY04NN  1572313188       870359649   \n",
       "\n",
       "                                             product_title product_category  \\\n",
       "0           Scotch Cushion Wrap 7961, 12 Inches x 100 Feet  Office Products   \n",
       "1                Dust-Off Compressed Gas Duster, Pack of 4  Office Products   \n",
       "2        Amram Tagger Standard Tag Attaching Tagging Gu...  Office Products   \n",
       "3        AmazonBasics 12-Sheet High-Security Micro-Cut ...  Office Products   \n",
       "4        Derwent Colored Pencils, Inktense Ink Pencils,...  Office Products   \n",
       "...                                                    ...              ...   \n",
       "2642429                 PalmOne III Leather Belt Clip Case  Office Products   \n",
       "2642430                 PalmOne III Leather Belt Clip Case  Office Products   \n",
       "2642431                  Gods and Heroes of Ancient Greece  Office Products   \n",
       "2642432  Microsoft EXCEL 97/ Visual Basic Step-by-Step ...  Office Products   \n",
       "2642433  Microsoft EXCEL 97/ Visual Basic Step-by-Step ...  Office Products   \n",
       "\n",
       "         star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0                  5              0            0    N                 Y   \n",
       "1                  5              0            1    N                 Y   \n",
       "2                  5              0            0    N                 Y   \n",
       "3                  1              2            3    N                 Y   \n",
       "4                  4              0            0    N                 Y   \n",
       "...              ...            ...          ...  ...               ...   \n",
       "2642429            4             26           26    N                 N   \n",
       "2642430            4             18           18    N                 N   \n",
       "2642431            4              9           16    N                 N   \n",
       "2642432            5              0            0    N                 N   \n",
       "2642433            5              0            0    N                 N   \n",
       "\n",
       "                                           review_headline  \\\n",
       "0                                               Five Stars   \n",
       "1        Phffffffft, Phfffffft. Lots of air, and it's C...   \n",
       "2                            but I am sure I will like it.   \n",
       "3        and the shredder was dirty and the bin was par...   \n",
       "4                                               Four Stars   \n",
       "...                                                    ...   \n",
       "2642429  Great value! A must if you hate to carry thing...   \n",
       "2642430          Attaches the Palm Pilot like an appendage   \n",
       "2642431  Excellent information, pictures and stories, I...   \n",
       "2642432                                         class text   \n",
       "2642433                                 Microsoft's Finest   \n",
       "\n",
       "                                               review_body review_date  \n",
       "0                                           Great product.  2015-08-31  \n",
       "1        What's to say about this commodity item except...  2015-08-31  \n",
       "2          Haven't used yet, but I am sure I will like it.  2015-08-31  \n",
       "3        Although this was labeled as &#34;new&#34; the...  2015-08-31  \n",
       "4                          Gorgeous colors and easy to use  2015-08-31  \n",
       "...                                                    ...         ...  \n",
       "2642429  I can't live anymore whithout my Palm III. But...  1998-12-07  \n",
       "2642430  Although the Palm Pilot is thin and compact it...  1998-11-30  \n",
       "2642431  This book had a lot of great content without b...  1998-10-15  \n",
       "2642432  I am teaching a course in Excel and am using t...  1998-08-22  \n",
       "2642433  A very comprehensive layout of exactly how Vis...  1998-07-15  \n",
       "\n",
       "[2642434 rows x 15 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dzV3Ny8hIK3v",
    "outputId": "ea481264-c91a-45cd-af69-ce55e74bdc09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2642434, 15)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-dhii6u99nQ"
   },
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "vMUY76jKIJAj"
   },
   "outputs": [],
   "source": [
    "df2=data[[\"star_rating\",\"review_body\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppJQc7u299nR"
   },
   "source": [
    " ## We form three classes and select 20000 reviews randomly from each class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "a_ktqjhb99nQ",
    "outputId": "471561e4-fbfd-4af3-8ead-6f986a95b921"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642429</th>\n",
       "      <td>4</td>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642430</th>\n",
       "      <td>4</td>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642431</th>\n",
       "      <td>4</td>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642432</th>\n",
       "      <td>5</td>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642433</th>\n",
       "      <td>5</td>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2642434 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body\n",
       "0                  5                                     Great product.\n",
       "1                  5  What's to say about this commodity item except...\n",
       "2                  5    Haven't used yet, but I am sure I will like it.\n",
       "3                  1  Although this was labeled as &#34;new&#34; the...\n",
       "4                  4                    Gorgeous colors and easy to use\n",
       "...              ...                                                ...\n",
       "2642429            4  I can't live anymore whithout my Palm III. But...\n",
       "2642430            4  Although the Palm Pilot is thin and compact it...\n",
       "2642431            4  This book had a lot of great content without b...\n",
       "2642432            5  I am teaching a course in Excel and am using t...\n",
       "2642433            5  A very comprehensive layout of exactly how Vis...\n",
       "\n",
       "[2642434 rows x 2 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "mhg2whle99nR"
   },
   "outputs": [],
   "source": [
    "sample_reviews = df2.sample(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "aex3U50isv2I",
    "outputId": "b7ff3d03-cad4-4641-8b7b-716d85828802"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225150</th>\n",
       "      <td>5</td>\n",
       "      <td>I have been through so many laptop trays, sigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141133</th>\n",
       "      <td>1</td>\n",
       "      <td>Bad phones, I sent them to Colombia and didn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361962</th>\n",
       "      <td>4</td>\n",
       "      <td>Simple small ring binder. Have used for years....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        star_rating                                        review_body\n",
       "225150            5  I have been through so many laptop trays, sigh...\n",
       "141133            1  Bad phones, I sent them to Colombia and didn't...\n",
       "361962            4  Simple small ring binder. Have used for years...."
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "n3aiFSeEs0PV"
   },
   "outputs": [],
   "source": [
    "rating_statistics = df2[\"star_rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFMNCfiFs3vs",
    "outputId": "163637a9-981a-40bd-c2a1-6f7f1c9fef5c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "star_rating\n",
       "5    1584192\n",
       "4     418694\n",
       "1     307234\n",
       "3     193818\n",
       "2     138496\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rating_statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet filters a DataFrame (`df2`) to categorize reviews based on their star ratings. It creates three subsets: `positive_reviews` for ratings 4 and 5, `negative_reviews` for ratings 1 and 2, and `neutral` for rating 3. Finally, it prints the number of reviews in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manan\\AppData\\Local\\Temp\\ipykernel_7980\\2420425920.py:1: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead.\n",
      "  positive_reviews = df2[(df2['star_rating'] == 4) + (df2['star_rating'] == 5)]\n",
      "C:\\Users\\Manan\\AppData\\Local\\Temp\\ipykernel_7980\\2420425920.py:2: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead.\n",
      "  negative_reviews = df2[(df2['star_rating'] == 1) + (df2['star_rating'] == 2)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of three classes: 2002886,445730,193818\n"
     ]
    }
   ],
   "source": [
    "positive_reviews = df2[(df2['star_rating'] == 4) + (df2['star_rating'] == 5)]\n",
    "negative_reviews = df2[(df2['star_rating'] == 1) + (df2['star_rating'] == 2)]\n",
    "neutral = df2[df2['star_rating'] == 3]\n",
    "\n",
    "print(\"Statistics of three classes:\", ','.join(map(str, [len(positive_reviews), len(negative_reviews), len(neutral)])))\n",
    "\n",
    "# print(\"\\nNumber of Positive Reviews:\", len(positive_reviews))\n",
    "# print(\"\\nNumber of Negative Reviews:\", len(negative_reviews))\n",
    "# print(\"\\nNumber of Neutral Reviews:\", len(neutral))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code adds a 'sentiment' column to `df2` based on 'star_rating': 1 for ratings > 3, 0 for <= 2, and None otherwise, using a lambda function and `apply`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZhTT-MOsn99",
    "outputId": "c720515f-743e-433c-90a0-98622ae9ebb7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manan\\AppData\\Local\\Temp\\ipykernel_7980\\1095391281.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['sentiment'] = df2['star_rating'].apply(lambda x: 1 if x > 3 else 0 if x <= 2 else None)\n"
     ]
    }
   ],
   "source": [
    "df2['sentiment'] = df2['star_rating'].apply(lambda x: 1 if x > 3 else 0 if x <= 2 else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove rows where 'sentiment' is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "id": "5GhmZAJM-k_N"
   },
   "outputs": [],
   "source": [
    "\n",
    "df2 = df2.dropna(subset=['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "zdNTG61ItizR",
    "outputId": "0d73c108-77a9-4492-9dd4-7915328c01af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>What's to say about this commodity item except...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Haven't used yet, but I am sure I will like it.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Although this was labeled as &amp;#34;new&amp;#34; the...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gorgeous colors and easy to use</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642429</th>\n",
       "      <td>4</td>\n",
       "      <td>I can't live anymore whithout my Palm III. But...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642430</th>\n",
       "      <td>4</td>\n",
       "      <td>Although the Palm Pilot is thin and compact it...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642431</th>\n",
       "      <td>4</td>\n",
       "      <td>This book had a lot of great content without b...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642432</th>\n",
       "      <td>5</td>\n",
       "      <td>I am teaching a course in Excel and am using t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642433</th>\n",
       "      <td>5</td>\n",
       "      <td>A very comprehensive layout of exactly how Vis...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2448616 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  \\\n",
       "0                  5                                     Great product.   \n",
       "1                  5  What's to say about this commodity item except...   \n",
       "2                  5    Haven't used yet, but I am sure I will like it.   \n",
       "3                  1  Although this was labeled as &#34;new&#34; the...   \n",
       "4                  4                    Gorgeous colors and easy to use   \n",
       "...              ...                                                ...   \n",
       "2642429            4  I can't live anymore whithout my Palm III. But...   \n",
       "2642430            4  Although the Palm Pilot is thin and compact it...   \n",
       "2642431            4  This book had a lot of great content without b...   \n",
       "2642432            5  I am teaching a course in Excel and am using t...   \n",
       "2642433            5  A very comprehensive layout of exactly how Vis...   \n",
       "\n",
       "         sentiment  \n",
       "0              1.0  \n",
       "1              1.0  \n",
       "2              1.0  \n",
       "3              0.0  \n",
       "4              1.0  \n",
       "...            ...  \n",
       "2642429        1.0  \n",
       "2642430        1.0  \n",
       "2642431        1.0  \n",
       "2642432        1.0  \n",
       "2642433        1.0  \n",
       "\n",
       "[2448616 rows x 3 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and Print the Number of positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "id": "GApkrdJPtrXk"
   },
   "outputs": [],
   "source": [
    "num_positive_reviews = df2[df2['sentiment'] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lj01Qc45trMg",
    "outputId": "70670b14-d8da-4c11-8c0a-e6798e1ea97c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002886"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_positive_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and print the number of negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "8HEUhhfWtwvT"
   },
   "outputs": [],
   "source": [
    "num_negative_reviews = df2[df2['sentiment'] == 0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VoiA4AYUt2rX",
    "outputId": "08296e8c-4b34-45cd-8037-c952a939e6ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445730"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_negative_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code selects a random sample of 100,000 rows from df2 where 'sentiment' is 1 (positive reviews) and another random sample of 100,000 rows where 'sentiment' is 0 (negative reviews). After we concat positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "fyp-Nfmxt2cu"
   },
   "outputs": [],
   "source": [
    "positive_reviews = df2[df2['sentiment'] == 1].sample(n=100000, random_state=55)\n",
    "negative_reviews = df2[df2['sentiment'] == 0].sample(n=100000, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "id": "AoPhICk8uqFU"
   },
   "outputs": [],
   "source": [
    "df3 = pd.concat([positive_reviews, negative_reviews])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "k-4vSQV3up18",
    "outputId": "b0f46013-0ea5-48ba-821f-00104c4e30b7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165183</th>\n",
       "      <td>5</td>\n",
       "      <td>Really cute. Holds like 16 cards</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179279</th>\n",
       "      <td>5</td>\n",
       "      <td>Great delivery time.  Also pleased with qualit...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336999</th>\n",
       "      <td>4</td>\n",
       "      <td>For the cost, you obviously can't beat it.  Th...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235220</th>\n",
       "      <td>5</td>\n",
       "      <td>I had originally ordered ink on eBay for my br...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210890</th>\n",
       "      <td>5</td>\n",
       "      <td>Very nice product, also very accurate. The onl...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731212</th>\n",
       "      <td>2</td>\n",
       "      <td>the measurement is 4x6 with flap open, I expec...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972938</th>\n",
       "      <td>1</td>\n",
       "      <td>Bought it to replace my old printhead because ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821662</th>\n",
       "      <td>2</td>\n",
       "      <td>It makes my Logitech M510 wireless mouse spora...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496005</th>\n",
       "      <td>1</td>\n",
       "      <td>My gripe is the poor support service, and warr...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607446</th>\n",
       "      <td>1</td>\n",
       "      <td>I purchased this battery because it is listed ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  \\\n",
       "165183             5                   Really cute. Holds like 16 cards   \n",
       "179279             5  Great delivery time.  Also pleased with qualit...   \n",
       "1336999            4  For the cost, you obviously can't beat it.  Th...   \n",
       "235220             5  I had originally ordered ink on eBay for my br...   \n",
       "210890             5  Very nice product, also very accurate. The onl...   \n",
       "...              ...                                                ...   \n",
       "1731212            2  the measurement is 4x6 with flap open, I expec...   \n",
       "972938             1  Bought it to replace my old printhead because ...   \n",
       "1821662            2  It makes my Logitech M510 wireless mouse spora...   \n",
       "496005             1  My gripe is the poor support service, and warr...   \n",
       "2607446            1  I purchased this battery because it is listed ...   \n",
       "\n",
       "         sentiment  \n",
       "165183         1.0  \n",
       "179279         1.0  \n",
       "1336999        1.0  \n",
       "235220         1.0  \n",
       "210890         1.0  \n",
       "...            ...  \n",
       "1731212        0.0  \n",
       "972938         0.0  \n",
       "1821662        0.0  \n",
       "496005         0.0  \n",
       "2607446        0.0  \n",
       "\n",
       "[200000 rows x 3 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8uB49rd9rWo"
   },
   "source": [
    "\n",
    "This code uses the train_test_split function from scikit-learn to split the DataFrame df3 into training (train_df) and testing (test_df) sets. The testing set comprises 20% of the original data, and the random state is set to 55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "id": "z02btk2Wuugc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df3, test_size=0.2, random_state=55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEcl6muy99nR"
   },
   "source": [
    "# Data Cleaning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "id": "_c6dwYY8vHiM"
   },
   "outputs": [],
   "source": [
    "from contractions import contractions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "id": "HOyXONU8vHYA"
   },
   "outputs": [],
   "source": [
    "# def expand_contractions1(text):\n",
    "#     for contraction, expansion in contractions_dict.items():\n",
    "#         text = re.sub(contraction, expansion, text)\n",
    "#     return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, `expand_contractions`, replaces English contractions in a given text with their expanded forms. It uses a dictionary (`contractions_dict`) mapping contractions to their expanded versions. The function iterates through the text and performs the replacement. Additionally, it checks if the input text is not NaN before applying the expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "LXeBEI9y3Y0f"
   },
   "outputs": [],
   "source": [
    "def expand_contractions(text):\n",
    "    contractions_dict = {\n",
    "        \"I'm\": \"I am\", \"you're\": \"you are\", \"he's\": \"he is\", \"she's\": \"she is\", \"it's\": \"it is\",\n",
    "        \"we're\": \"we are\", \"they're\": \"they are\", \"I've\": \"I have\", \"you've\": \"you have\", \"we've\": \"we have\",\n",
    "        \"they've\": \"they have\", \"I'll\": \"I will\", \"you'll\": \"you will\", \"he'll\": \"he will\", \"she'll\": \"she will\",\n",
    "        \"it'll\": \"it will\", \"we'll\": \"we will\", \"they'll\": \"they will\", \"isn't\": \"is not\", \"aren't\": \"are not\",\n",
    "        \"wasn't\": \"was not\", \"weren't\": \"were not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"hadn't\": \"had not\",\n",
    "        \"won't\": \"will not\", \"wouldn't\": \"would not\", \"don't\": \"do not\", \"doesn't\": \"does not\", \"didn't\": \"did not\",\n",
    "        \"can't\": \"cannot\", \"cannot\": \"can not\", \"couldn't\": \"could not\", \"shouldn't\": \"should not\", \"mustn't\": \"must not\",\n",
    "        \"mightn't\": \"might not\", \"I'd\": \"I would\", \"you'd\": \"you would\", \"he'd\": \"he would\", \"she'd\": \"she would\",\n",
    "        \"it'd\": \"it would\", \"we'd\": \"we would\", \"they'd\": \"they would\", \"let's\": \"let us\", \"that's\": \"that is\",\n",
    "        \"who's\": \"who is\", \"what's\": \"what is\", \"where's\": \"where is\", \"when's\": \"when is\", \"why's\": \"why is\",\n",
    "        \"how's\": \"how is\", \"here's\": \"here is\", \"there's\": \"there is\", \"that'll\": \"that will\", \"who'll\": \"who will\",\n",
    "        \"what'll\": \"what will\", \"where'll\": \"where will\", \"when'll\": \"when will\", \"why'll\": \"why will\", \"how'll\": \"how will\",\n",
    "        \"here'll\": \"here will\", \"there'll\": \"there will\", \"can've\": \"can have\", \"could've\": \"could have\", \"would've\": \"would have\",\n",
    "        \"should've\": \"should have\", \"must've\": \"must have\", \"might've\": \"might have\", \"ought to've\": \"ought to have\", \"I'd've\": \"I would have\",\n",
    "        \"you'd've\": \"you would have\", \"he'd've\": \"he would have\", \"she'd've\": \"she would have\", \"it'd've\": \"it would have\",\n",
    "        \"we'd've\": \"we would have\",  \"ain't\": \"am not\", \"gimme\": \"give me\", \"gonna\": \"going to\",\n",
    "        \"gotta\": \"got to\", \"dunno\": \"do not know\", \"kinda\": \"kind of\", \"lemme\": \"let me\", \"wanna\": \"want to\", \"shoulda\": \"should have\",\n",
    "        \"coulda\": \"could have\", \"woulda\": \"would have\", \"musta\": \"must have\", \"mighta\": \"might have\", \"oughta\": \"ought to\",\n",
    "        \"mayn't\": \"may not\", \"e'er\": \"ever\", \"ne'er\": \"never\", \"o'er\": \"over\", \"'tis\": \"it is\", \"'twas\": \"it was\",\n",
    "        \"'twill\": \"it will\", \"y'all\": \"you all\",\"she'd've\": \"she would have\", \"it'd've\": \"it would have\", \"we'd've\": \"we would have\",\n",
    "        \"they'd've\": \"they would have\", \"should've\": \"should have\", \"must've\": \"must have\",    \"might've\": \"might have\", \"ought to've\": \"ought to have\", \"I'd've\": \"I would have\",\n",
    "        \"you'd've\": \"you would have\", \"he'd've\": \"he would have\", \"that'd\": \"that would\",\"who'd've\": \"who would have\", \"what'd\": \"what would\", \"where'd\": \"where did\",\n",
    "        \"when'd\": \"when did\", \"why'd\": \"why did\", \"how'd\": \"how did\", \"there'd\": \"there would\",\n",
    "        \"can've\": \"can have\", \"could've\": \"could have\", \"would've\": \"would have\", \"should've\": \"should have\",\n",
    "        \"might've\": \"might have\", \"ought to've\": \"ought to have\", \"I'd've\": \"I would have\", \"you'd've\": \"you would have\",\n",
    "        \"he'd've\": \"he would have\", \"she'd've\": \"she would have\", \"it'd've\": \"it would have\", \"we'd've\": \"we would have\",\n",
    "        \"they'd've\": \"they would have\", \"ain't\": \"am not\", \"gimme\": \"give me\", \"gonna\": \"going to\", \"gotta\": \"got to\",\n",
    "        \"dunno\": \"do not know\", \"kinda\": \"kind of\", \"lemme\": \"let me\", \"wanna\": \"want to\", \"shoulda\": \"should have\",\n",
    "        \"coulda\": \"could have\", \"woulda\": \"would have\", \"musta\": \"must have\", \"mighta\": \"might have\", \"oughta\": \"ought to\",\n",
    "        \"mayn't\": \"may not\", \"e'er\": \"ever\", \"ne'er\": \"never\", \"o'er\": \"over\", \"'tis\": \"it is\", \"'twas\": \"it was\",\n",
    "        \"'twill\": \"it will\", \"y'all\": \"you all\", \"amn't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"could've\": \"could have\",\n",
    "        \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
    "        \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\",\n",
    "        \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\",\n",
    "        \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\n",
    "        \"I'm\": \"I am\", \"I've\": \"I have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\",\n",
    "        \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "        \"mayn't\": \"may not\", \"might've\": \"might have\", \"mightn't\": \"might not\", \"mightn't've\": \"might not have\",\n",
    "        \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "        \"needn't've\": \"need not have\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "        \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\",\n",
    "        \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\",\n",
    "        \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"so's\": \"so is\",\n",
    "        \"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that'll\": \"that will\", \"that'll've\": \"that will have\",\n",
    "        \"that's\": \"that is\"\n",
    "    }\n",
    "    if pd.notna(text):\n",
    "        for contraction, expanded_form in contractions_dict.items():\n",
    "            text = text.replace(contraction, expanded_form)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet performs several text cleaning operations on the 'review_body' column of DataFrame `df3`:\n",
    "\n",
    "1. Converts 'review_body' to string type.\n",
    "2. Converts all reviews to lowercase.\n",
    "3. Removes HTML tags and URLs from the reviews.\n",
    "4. Removes non-alphabetical characters.\n",
    "5. Removes extra spaces.\n",
    "6. Applies the `expand_contractions` function to handle contractions in the cleaned reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "id": "L9l5zRf8w_XF"
   },
   "outputs": [],
   "source": [
    "df3['review_body'] = df3['review_body'].astype(str)\n",
    "\n",
    "# Convert all reviews to lowercase\n",
    "df3['cleaned_reviews'] = df3['review_body'].str.lower()\n",
    "\n",
    "# Remove HTML and URLs\n",
    "df3['cleaned_reviews'] = df3['cleaned_reviews'].replace({'<.*?>': '', 'http\\S+': ''}, regex=True)\n",
    "\n",
    "# Remove non-alphabetical characters\n",
    "df3['cleaned_reviews'] = df3['cleaned_reviews'].replace({'[^a-zA-Z\\s]': ''}, regex=True)\n",
    "\n",
    "# Remove extra spaces\n",
    "df3['cleaned_reviews'] = df3['cleaned_reviews'].replace({'\\s+': ' '}, regex=True).str.strip()\n",
    "\n",
    "# # Replace null values with 'NA'\n",
    "# df3['cleaned_reviews'].fillna('NA', inplace=True)\n",
    "\n",
    "# Perform contractions\n",
    "df3['cleaned_reviews'] = df3['cleaned_reviews'].apply(expand_contractions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate and Print average length of reviews before and after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "id": "QGeilDNHw_Tr"
   },
   "outputs": [],
   "source": [
    "avg_length_before = df3['review_body'].apply(len).mean()\n",
    "avg_length_after = df3['cleaned_reviews'].apply(len).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-DdvU-VPw_RN",
    "outputId": "45bc6e0e-b659-4400-e231-f7b9c86b7b7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of Reviews Before and After Cleaning: 318.87, 301.02\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average Length of Reviews Before and After Cleaning: {avg_length_before:.2f}, {avg_length_after:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "qxj-jESEw_O5",
    "outputId": "e30bf583-7f2b-413c-e1ed-3b6c914f393f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165183</th>\n",
       "      <td>5</td>\n",
       "      <td>Really cute. Holds like 16 cards</td>\n",
       "      <td>1.0</td>\n",
       "      <td>really cute holds like cards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179279</th>\n",
       "      <td>5</td>\n",
       "      <td>Great delivery time.  Also pleased with qualit...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>great delivery time also pleased with quality ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336999</th>\n",
       "      <td>4</td>\n",
       "      <td>For the cost, you obviously can't beat it.  Th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>for the cost you obviously cant beat it they s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235220</th>\n",
       "      <td>5</td>\n",
       "      <td>I had originally ordered ink on eBay for my br...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had originally ordered ink on ebay for my br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210890</th>\n",
       "      <td>5</td>\n",
       "      <td>Very nice product, also very accurate. The onl...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>very nice product also very accurate the only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731212</th>\n",
       "      <td>2</td>\n",
       "      <td>the measurement is 4x6 with flap open, I expec...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the measurement is x with flap open i expected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972938</th>\n",
       "      <td>1</td>\n",
       "      <td>Bought it to replace my old printhead because ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bought it to replace my old printhead because ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821662</th>\n",
       "      <td>2</td>\n",
       "      <td>It makes my Logitech M510 wireless mouse spora...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>it makes my logitech m wireless mouse sporadic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496005</th>\n",
       "      <td>1</td>\n",
       "      <td>My gripe is the poor support service, and warr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>my gripe is the poor support service and warra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607446</th>\n",
       "      <td>1</td>\n",
       "      <td>I purchased this battery because it is listed ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i purchased this battery because it is listed ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  \\\n",
       "165183             5                   Really cute. Holds like 16 cards   \n",
       "179279             5  Great delivery time.  Also pleased with qualit...   \n",
       "1336999            4  For the cost, you obviously can't beat it.  Th...   \n",
       "235220             5  I had originally ordered ink on eBay for my br...   \n",
       "210890             5  Very nice product, also very accurate. The onl...   \n",
       "...              ...                                                ...   \n",
       "1731212            2  the measurement is 4x6 with flap open, I expec...   \n",
       "972938             1  Bought it to replace my old printhead because ...   \n",
       "1821662            2  It makes my Logitech M510 wireless mouse spora...   \n",
       "496005             1  My gripe is the poor support service, and warr...   \n",
       "2607446            1  I purchased this battery because it is listed ...   \n",
       "\n",
       "         sentiment                                    cleaned_reviews  \n",
       "165183         1.0                       really cute holds like cards  \n",
       "179279         1.0  great delivery time also pleased with quality ...  \n",
       "1336999        1.0  for the cost you obviously cant beat it they s...  \n",
       "235220         1.0  i had originally ordered ink on ebay for my br...  \n",
       "210890         1.0  very nice product also very accurate the only ...  \n",
       "...            ...                                                ...  \n",
       "1731212        0.0  the measurement is x with flap open i expected...  \n",
       "972938         0.0  bought it to replace my old printhead because ...  \n",
       "1821662        0.0  it makes my logitech m wireless mouse sporadic...  \n",
       "496005         0.0  my gripe is the poor support service and warra...  \n",
       "2607446        0.0  i purchased this battery because it is listed ...  \n",
       "\n",
       "[200000 rows x 4 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G6K0ewK_pbK"
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p4qsIhlD_7zd",
    "outputId": "6b3262ad-7123-4e7e-cc86-36733191371a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Manan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Manan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Manan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5P0isU0V99nS"
   },
   "source": [
    "## Remove the stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function, `remove_stopwords`, takes a text as input and removes common English stop words while retaining a specific set of negative words. It utilizes the NLTK library for tokenization and the list of negative words to exclude them from the stop words removal process. The filtered tokens are then joined back into a cleaned text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "id": "IFO77IJg99nT"
   },
   "outputs": [],
   "source": [
    "\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # List of negative words to exclude from the stopwords\n",
    "    negative_words = ['not', 'no', 'never', 'none', 'neither', 'nor', 'nothing', 'nowhere','nobody', 'noway', 'nothing', 'nowhere', 'hardly', 'scarcely', 'barely', 'rarely', 'neither', 'nor',\n",
    "    'nevertheless', 'nonetheless', 'notwithstanding', 'no', 'none', 'nope', 'no way', 'noway', 'noways',\n",
    "    'nowhere near', 'nothing doing', 'nothing else', 'nothing more', 'nothing special', 'nothing to it',\n",
    "    'nothing to lose', 'nothing to sneeze at', 'nothing to write home about', 'nothing ventured', 'nothingness',\n",
    "    'not likely', 'not right', 'not up to it', 'notwithstanding', 'now and again', 'now and then', 'now or never',\n",
    "    'null and void', 'nurture', 'obstruction', 'obtuse', 'obviously', 'occlude', 'odd', 'off', 'offend',\n",
    "    'offense', 'offensive', 'officious', 'ominous', 'on the contrary', 'on the other hand', 'once', 'onerous',\n",
    "    'only', 'opaque', 'open question', 'oppose', 'opposition', 'oppress', 'oppressive', 'or else', 'or', 'order',\n",
    "    'ordinarily', 'ought not', 'ought', 'overbearing', 'overpowering', 'oversight', 'overthrow', 'overwhelm',\n",
    "    'overwhelming', 'pain', 'painful', 'paradox', 'paradoxical', 'paranoid', 'patronize', 'pause', 'pejorative',\n",
    "    'peril', 'perilous', 'pernicious', 'perplex', 'perplexity', 'persecute', 'pertinacious', 'perverse',\n",
    "    'perversion', 'perversity', 'pervert', 'pessimism', 'pessimistic', 'pest', 'petrify', 'pillage', 'pique',\n",
    "    'piss', 'pissed off', 'pissing', 'piteous', 'pitiable', 'pitiful', 'pity', 'pitying', 'plague', 'play down',\n",
    "    'play off', 'plea', 'plead']\n",
    "    \n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Filter out stop words excluding negative words that are mentioned above in the negative words list\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words or word.lower() in negative_words]\n",
    "    \n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XON2jqqE99nT"
   },
   "source": [
    "## Perform lemmatization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "id": "0APpnbex99nT"
   },
   "outputs": [],
   "source": [
    "# Function to perform lemmatization\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for overall preprocessing which calls stopwords and lemmatization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "U6EdK7hAAG5X"
   },
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    cleaned_text = text.lower()\n",
    "    cleaned_text = remove_stopwords(cleaned_text)\n",
    "    cleaned_text = lemmatize_text(cleaned_text)\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "id": "Td3EhDRIALMu"
   },
   "outputs": [],
   "source": [
    "# Apply preprocessing to the entire dataset\n",
    "df3['processed_reviews'] = df3['cleaned_reviews'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print three sample reviews before and after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "A-PnTmjGCgGz"
   },
   "outputs": [],
   "source": [
    "\n",
    "sample_reviews = df3[['cleaned_reviews', 'processed_reviews']].sample(3, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wG2ZFtg0Ck-D",
    "outputId": "879666e8-39ef-452a-b71c-30717002491a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOriginal Review:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'this product wouldnt even be worth getting in a dollar store sheet strip it regularly has problems just doing i typically try to do sheets at a time and every times it gets jammed and of course they dont have a way to open it to clear the jammed paper out so i have to try to use a butter knife takes longer doing that every sheets than using a pair of scissors to shred the sheets i literally would not pay for this'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nProcessed Review:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'product wouldnt even worth getting dollar store sheet strip regularly problem typically try sheet time every time get jammed course dont way open clear jammed paper try use butter knife take longer every sheet using pair scissors shred sheet literally would not pay'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nOriginal Review:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'after using the telo wireless adapter with our ooma purchased from costco in may for about months i finally pulled the plug and went back to a direct connect to our dsl modemwe have dsl through century link into an actiontec q dsl modem with wifi our download speed via speedtestnet is mb and upload is just shy of mbthe adapter did establish a wireless connection with the q but would drop the connection at least every other day or so and sometimes daily reestablishing would require a power cycle of the ooma unit with the adapter attached to it in frustration with that situation i decided to disable the radio on the q and try an apple airport extreme circa which is an extremely straightforward wifi unit it also has a more powerful radio than the q as evidenced by signal level detected by other devices i set it up with a ssid and password with wpa security no matter what i did the ooma adapter would not ever establish a connection i contacted ooma and they said to set qos to down up i tried that to no avail also tried from some forums and that did not help i tried other security types and both aes and tkip and none of that mattered ive thrown in the towel and have direct connected the telo to the q lan portthis is a drag because i had cross wired the house phone port i was previously using to feed the rest of the house and now i have to screw around with that again for a different room and mess with the punchdown and butt set etcat the end of the day i have to say the telo wireless adapter is probably more junk than not or at the very least it is very finicky about establishing and holding wifi connections maybe in a year or two they will cook up something more reliable'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nProcessed Review:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'using telo wireless adapter ooma purchased costco may month finally pulled plug went back direct connect dsl modemwe dsl century link actiontec q dsl modem wifi download speed via speedtestnet mb upload shy mbthe adapter establish wireless connection q would drop connection least every day or sometimes daily reestablishing would require power cycle ooma unit adapter attached frustration situation decided disable radio q try apple airport extreme circa extremely straightforward wifi unit also powerful radio q evidenced signal level detected device set ssid password wpa security no matter ooma adapter would not ever establish connection contacted ooma said set qos tried no avail also tried forum not help tried security type aes tkip none mattered ive thrown towel direct connected telo q lan portthis drag cross wired house phone port previously using feed rest house screw around different room mess punchdown butt set etcat end day say telo wireless adapter probably junk not or least finicky establishing holding wifi connection maybe year or two cook something reliable'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nOriginal Review:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'i opened the black ink cartridge and i now have ink on my desk and every single finger and thumb price was great but definitely not worth the messwill not buy again'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nProcessed Review:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'opened black ink cartridge ink desk every single finger thumb price great definitely not worth messwill not buy'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for index, row in sample_reviews.iterrows():\n",
    "    display(\"\\nOriginal Review:\", row['cleaned_reviews'])\n",
    "    display(\"\\nProcessed Review:\", row['processed_reviews'])\n",
    "    display(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDcqfXs1ANyD"
   },
   "source": [
    "Print average length of reviews before and after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4CvzYq4AUMu",
    "outputId": "a96157af-bddb-47ab-ec5a-41adaefa7983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of Reviews Before and After Preprocessing: 301.02, 196.14\n"
     ]
    }
   ],
   "source": [
    "\n",
    "avg_length_before = df3['cleaned_reviews'].apply(len).mean()\n",
    "avg_length_after = df3['processed_reviews'].apply(len).mean()\n",
    "print(f\"Average Length of Reviews Before and After Preprocessing: {avg_length_before:.2f}, {avg_length_after:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "GW-SzEUQDX3J",
    "outputId": "9fe22078-7b46-4be3-f106-c98d9eb8f260"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_reviews</th>\n",
       "      <th>processed_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>165183</th>\n",
       "      <td>5</td>\n",
       "      <td>Really cute. Holds like 16 cards</td>\n",
       "      <td>1.0</td>\n",
       "      <td>really cute holds like cards</td>\n",
       "      <td>really cute hold like card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179279</th>\n",
       "      <td>5</td>\n",
       "      <td>Great delivery time.  Also pleased with qualit...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>great delivery time also pleased with quality ...</td>\n",
       "      <td>great delivery time also pleased quality paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336999</th>\n",
       "      <td>4</td>\n",
       "      <td>For the cost, you obviously can't beat it.  Th...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>for the cost you obviously cant beat it they s...</td>\n",
       "      <td>cost obviously cant beat seem longer lasting o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235220</th>\n",
       "      <td>5</td>\n",
       "      <td>I had originally ordered ink on eBay for my br...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>i had originally ordered ink on ebay for my br...</td>\n",
       "      <td>originally ordered ink ebay brother mfcjdw rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210890</th>\n",
       "      <td>5</td>\n",
       "      <td>Very nice product, also very accurate. The onl...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>very nice product also very accurate the only ...</td>\n",
       "      <td>nice product also accurate only thing didnt li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731212</th>\n",
       "      <td>2</td>\n",
       "      <td>the measurement is 4x6 with flap open, I expec...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>the measurement is x with flap open i expected...</td>\n",
       "      <td>measurement x flap open expected envelope fit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972938</th>\n",
       "      <td>1</td>\n",
       "      <td>Bought it to replace my old printhead because ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bought it to replace my old printhead because ...</td>\n",
       "      <td>bought replace old printhead error code statin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1821662</th>\n",
       "      <td>2</td>\n",
       "      <td>It makes my Logitech M510 wireless mouse spora...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>it makes my logitech m wireless mouse sporadic...</td>\n",
       "      <td>make logitech wireless mouse sporadic say righ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496005</th>\n",
       "      <td>1</td>\n",
       "      <td>My gripe is the poor support service, and warr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>my gripe is the poor support service and warra...</td>\n",
       "      <td>gripe poor support service warranty used excel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607446</th>\n",
       "      <td>1</td>\n",
       "      <td>I purchased this battery because it is listed ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>i purchased this battery because it is listed ...</td>\n",
       "      <td>purchased battery listed replacement sony bpt ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         star_rating                                        review_body  \\\n",
       "165183             5                   Really cute. Holds like 16 cards   \n",
       "179279             5  Great delivery time.  Also pleased with qualit...   \n",
       "1336999            4  For the cost, you obviously can't beat it.  Th...   \n",
       "235220             5  I had originally ordered ink on eBay for my br...   \n",
       "210890             5  Very nice product, also very accurate. The onl...   \n",
       "...              ...                                                ...   \n",
       "1731212            2  the measurement is 4x6 with flap open, I expec...   \n",
       "972938             1  Bought it to replace my old printhead because ...   \n",
       "1821662            2  It makes my Logitech M510 wireless mouse spora...   \n",
       "496005             1  My gripe is the poor support service, and warr...   \n",
       "2607446            1  I purchased this battery because it is listed ...   \n",
       "\n",
       "         sentiment                                    cleaned_reviews  \\\n",
       "165183         1.0                       really cute holds like cards   \n",
       "179279         1.0  great delivery time also pleased with quality ...   \n",
       "1336999        1.0  for the cost you obviously cant beat it they s...   \n",
       "235220         1.0  i had originally ordered ink on ebay for my br...   \n",
       "210890         1.0  very nice product also very accurate the only ...   \n",
       "...            ...                                                ...   \n",
       "1731212        0.0  the measurement is x with flap open i expected...   \n",
       "972938         0.0  bought it to replace my old printhead because ...   \n",
       "1821662        0.0  it makes my logitech m wireless mouse sporadic...   \n",
       "496005         0.0  my gripe is the poor support service and warra...   \n",
       "2607446        0.0  i purchased this battery because it is listed ...   \n",
       "\n",
       "                                         processed_reviews  \n",
       "165183                          really cute hold like card  \n",
       "179279   great delivery time also pleased quality paper...  \n",
       "1336999  cost obviously cant beat seem longer lasting o...  \n",
       "235220   originally ordered ink ebay brother mfcjdw rec...  \n",
       "210890   nice product also accurate only thing didnt li...  \n",
       "...                                                    ...  \n",
       "1731212  measurement x flap open expected envelope fit ...  \n",
       "972938   bought replace old printhead error code statin...  \n",
       "1821662  make logitech wireless mouse sporadic say righ...  \n",
       "496005   gripe poor support service warranty used excel...  \n",
       "2607446  purchased battery listed replacement sony bpt ...  \n",
       "\n",
       "[200000 rows x 5 columns]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwSR2reI99nT"
   },
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet performs the following tasks:\n",
    "\n",
    "1. Splits the dataset into training and testing sets (`X_train`, `X_test`, `y_train`, `y_test`) using 80-20 ratio.\n",
    "2. Creates a TF-IDF (Term Frequency-Inverse Document Frequency) vectorizer (`tfidf_vectorizer`).\n",
    "3. Fits and transforms the training data (`X_train_tfidf`) using the TF-IDF vectorizer.\n",
    "4. Transforms the testing data (`X_test_tfidf`) using the same vectorizer.\n",
    "\n",
    "The resulting `X_train_tfidf` and `X_test_tfidf` contain the TF-IDF features for the training and testing sets, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "id": "7D3D_Z0799nT"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df3['processed_reviews'], df3['sentiment'], test_size=0.2, random_state=55)\n",
    "\n",
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_azM-K5L99nT"
   },
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses a Perceptron model for binary classification on TF-IDF features. It trains the model, makes predictions on training and testing sets, and calculates and prints accuracy, precision, recall, and F1-score for both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11HlU-iG99nU",
    "outputId": "900ef133-fb2a-4e83-b669-56d2fd47c457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perception Results: 0.9260875 , 0.9512191893251436 , 0.8982349558738969 , 0.923968111096824 , 0.8682 , 0.8916303307455068 , 0.8383161683831617 , 0.8641517212945784\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Create and train a Perceptron model\n",
    "perceptron_model = Perceptron()\n",
    "perceptron_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions on training set\n",
    "train_predictions = perceptron_model.predict(X_train_tfidf)\n",
    "\n",
    "# Predictions on testing set\n",
    "test_predictions = perceptron_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate metrics for training set\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "# Calculate metrics for testing set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "print(\"\\nPerception Results:\", train_accuracy, ',', train_precision, ',', train_recall, ',', train_f1, ',', test_accuracy, ',', test_precision, ',', test_recall, ',', test_f1)\n",
    "\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Results for Perceptron\")\n",
    "# print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
    "# print(f\"\\nTraining Precision: {train_precision:.4f}\")\n",
    "# print(f\"\\nTraining Recall: {train_recall:.4f}\")\n",
    "# print(f\"\\nTraining F1-Score: {train_f1:.4f}\")\n",
    "\n",
    "# print(f\"\\nTesting Accuracy: {test_accuracy:.4f}\")\n",
    "# print(f\"\\nTesting Precision: {test_precision:.4f}\")\n",
    "# print(f\"\\nTesting Recall: {test_recall:.4f}\")\n",
    "# print(f\"\\nTesting F1-Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ATDEue499nU"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code employs a Linear Support Vector Classification (LinearSVC) model for binary classification on TF-IDF features. It trains the model, makes predictions on training and testing sets, and calculates and prints accuracy, precision, recall, and F1-score for both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yxn-pfYq99nU",
    "outputId": "f358b9f2-a6df-4cf3-b8fc-f61d456b1943"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manan\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SVM Results: 0.94930625 , 0.9513190442108964 , 0.947073676841921 , 0.9491916135781356 , 0.9054 , 0.9060997596153846 , 0.9045595440455955 , 0.9053289967475606\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "linear_svc_model = LinearSVC()\n",
    "linear_svc_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions on training set\n",
    "train_predictions = linear_svc_model.predict(X_train_tfidf)\n",
    "\n",
    "# Predictions on testing set\n",
    "test_predictions = linear_svc_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate metrics for training set\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "# Calculate metrics for testing set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "\n",
    "print(\"\\n SVM Results:\", train_accuracy, ',', train_precision, ',', train_recall, ',', train_f1, ',', test_accuracy, ',', test_precision, ',', test_recall, ',', test_f1)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"\\nResults for SVM\")\n",
    "# print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
    "# print(f\"\\nTraining Precision: {train_precision:.4f}\")\n",
    "# print(f\"\\nTraining Recall: {train_recall:.4f}\")\n",
    "# print(f\"\\nTraining F1-Score: {train_f1:.4f}\")\n",
    "\n",
    "# print(f\"\\nTesting Accuracy: {test_accuracy:.4f}\")\n",
    "# print(f\"\\nTesting Precision: {test_precision:.4f}\")\n",
    "# print(f\"\\nTesting Recall: {test_recall:.4f}\")\n",
    "# print(f\"\\nTesting F1-Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8A6ogdQq99nU"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code uses a Logistic Regression model for binary classification on TF-IDF features. It trains the model, makes predictions on training and testing sets, and calculates and prints accuracy, precision, recall, and F1-score for both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W9KSWQ_z99nU",
    "outputId": "d2d9e293-52cc-478d-b754-baf2d5347ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Results: 0.92381875 , 0.927369442728751 , 0.9196604915122878 , 0.9234988796907068 , 0.90935 , 0.912327525430557 , 0.9057594240575942 , 0.9090316106372303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Create and train a Logistic Regression model\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions on training set\n",
    "train_predictions = logreg_model.predict(X_train_tfidf)\n",
    "\n",
    "# Predictions on testing set\n",
    "test_predictions = logreg_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate metrics for training set\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions)\n",
    "train_recall = recall_score(y_train, train_predictions)\n",
    "train_f1 = f1_score(y_train, train_predictions)\n",
    "\n",
    "# Calculate metrics for testing set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions)\n",
    "test_recall = recall_score(y_test, test_predictions)\n",
    "test_f1 = f1_score(y_test, test_predictions)\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\", train_accuracy, ',', train_precision, ',', train_recall, ',', train_f1, ',', test_accuracy, ',', test_precision, ',', test_recall, ',', test_f1)\n",
    "\n",
    "# # Print the results\n",
    "# print(\"Results for Logistic Regression\")\n",
    "# print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
    "# print(f\"\\nTraining Precision: {train_precision:.4f}\")\n",
    "# print(f\"\\nTraining Recall: {train_recall:.4f}\")\n",
    "# print(f\"\\nTraining F1-Score: {train_f1:.4f}\")\n",
    "\n",
    "# print(f\"\\nTesting Accuracy: {test_accuracy:.4f}\")\n",
    "# print(f\"\\nTesting Precision: {test_precision:.4f}\")\n",
    "# print(f\"\\nTesting Recall: {test_recall:.4f}\")\n",
    "# print(f\"\\nTesting F1-Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxCn0JsE99nU"
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code utilizes a Multinomial Naive Bayes model for binary classification on TF-IDF features. It trains the model, makes predictions on training and testing sets, and calculates and prints accuracy, precision, recall, and F1-score for both sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fm25lId99nU",
    "outputId": "5c9d2cc4-8b67-4625-fc4d-eb5239f75a7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bias: 0.88473125 , 0.886146224230536 , 0.88473125 , 0.8846254567772815 , 0.86365 , 0.8651842871079196 , 0.86365 , 0.8635071579723408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions on training set\n",
    "train_predictions = nb_model.predict(X_train_tfidf)\n",
    "\n",
    "# Predictions on testing set\n",
    "test_predictions = nb_model.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate metrics for training set\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "train_precision = precision_score(y_train, train_predictions, average='weighted')\n",
    "train_recall = recall_score(y_train, train_predictions, average='weighted')\n",
    "train_f1 = f1_score(y_train, train_predictions, average='weighted')\n",
    "\n",
    "# Calculate metrics for testing set\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "test_precision = precision_score(y_test, test_predictions, average='weighted')\n",
    "test_recall = recall_score(y_test, test_predictions, average='weighted')\n",
    "test_f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Average length of reviews before and after data cleaning:\", avg_length_before_cleaning, ',', avg_length_after_cleaning)\n",
    "#print(\"Average length of reviews before and after data preprocessing:\", avg_length_before_preprocessing, ',', avg_length_after_preprocessing)\n",
    "\n",
    "print(\"\\nNaive Bias:\", train_accuracy, ',', train_precision, ',', train_recall, ',', train_f1, ',', test_accuracy, ',', test_precision, ',', test_recall, ',', test_f1)\n",
    "\n",
    "# print(\"\\nResults for Naive Bias\")\n",
    "# print(f\"\\nTraining Accuracy: {train_accuracy:.4f}\")\n",
    "# print(f\"\\nTraining Precision: {train_precision:.4f}\")\n",
    "# print(f\"\\nTraining Recall: {train_recall:.4f}\")\n",
    "# print(f\"\\nTraining F1-Score: {train_f1:.4f}\")\n",
    "\n",
    "# print(f\"\\nTesting Accuracy: {test_accuracy:.4f}\")\n",
    "# print(f\"\\nTesting Precision: {test_precision:.4f}\")\n",
    "# print(f\"\\nTesting Recall: {test_recall:.4f}\")\n",
    "# print(f\"\\nTesting F1-Score: {test_f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "vA2WRn-GLeS9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics of three classes: 2002886,445730,193818\n",
      "Average Length of Reviews Before and After Cleaning: 318.87, 301.02\n",
      "Average Length of Reviews Before and After Preprocessing: 301.02, 196.14\n",
      "\n",
      "Perception Results: 0.9260875 , 0.9512191893251436 , 0.8982349558738969 , 0.923968111096824 , 0.8682 , 0.8916303307455068 , 0.8383161683831617 , 0.8641517212945784\n",
      "\n",
      " SVM Results: 0.9493125 , 0.9513309894525365 , 0.947073676841921 , 0.9491975594783197 , 0.9054 , 0.9060997596153846 , 0.9045595440455955 , 0.9053289967475606\n",
      "\n",
      "Logistic Regression Results: 0.92381875 , 0.927369442728751 , 0.9196604915122878 , 0.9234988796907068 , 0.90935 , 0.912327525430557 , 0.9057594240575942 , 0.9090316106372303\n",
      "\n",
      "Naive Bias: 0.88473125 , 0.886146224230536 , 0.88473125 , 0.8846254567772815 , 0.86365 , 0.8651842871079196 , 0.86365 , 0.8635071579723408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Manan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\Manan\\HW1_CSCI544.py:85: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead.\n",
      "  positive_reviews = df2[(df2['star_rating'] == 4) + (df2['star_rating'] == 5)]\n",
      "C:\\Users\\Manan\\HW1_CSCI544.py:86: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead.\n",
      "  negative_reviews = df2[(df2['star_rating'] == 1) + (df2['star_rating'] == 2)]\n",
      "C:\\Users\\Manan\\HW1_CSCI544.py:89: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead.\n",
      "  positive_reviewsf = df2[(df2['star_rating'] == 4) + (df2['star_rating'] == 5)]\n",
      "C:\\Users\\Manan\\HW1_CSCI544.py:90: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead.\n",
      "  negative_reviewsf = df2[(df2['star_rating'] == 1) + (df2['star_rating'] == 2)]\n",
      "C:\\Users\\Manan\\HW1_CSCI544.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2['sentiment'] = df2['star_rating'].apply(lambda x: 1 if x > 3 else 0 if x <= 2 else None)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Manan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Manan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Manan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python HW1_CSCI544.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
